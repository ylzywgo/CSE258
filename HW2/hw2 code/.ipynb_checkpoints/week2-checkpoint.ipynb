{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from urllib.request import urlopen\n",
    "import scipy.optimize\n",
    "import random\n",
    "from sklearn import svm\n",
    "from sklearn import linear_model\n",
    "\n",
    "def parseDataFromURL(fname):\n",
    "  for l in urlopen(fname):\n",
    "    yield eval(l)\n",
    "\n",
    "def parseData(fname):\n",
    "  for l in open(fname):\n",
    "    yield eval(l)\n",
    "\n",
    "print(\"Reading data...\")\n",
    "# Download from http://jmcauley.ucsd.edu/cse258/data/amazon/book_descriptions_50000.json\n",
    "data = list(parseData(\"data/amazon/book_descriptions_50000.json\"))\n",
    "print(\"done\")\n",
    "\n",
    "### Naive bayes to determine p(childrens book | mentions wizards and mentions witches) ###\n",
    "\n",
    "# p(childrens book)\n",
    "prior = [\"Children's Books\" in b['categories'] for b in data]\n",
    "prior = sum(prior) * 1.0 / len(prior)\n",
    "\n",
    "# p(isn't children's book)\n",
    "prior_neg = 1 - prior\n",
    "\n",
    "# p(mentions wizards | is childrens)\n",
    "p1 = ['wizard' in b['description'] for b in data if \"Children's Books\" in b['categories']]\n",
    "p1 = sum(p1) * 1.0 / len(p1)\n",
    "\n",
    "# p(mentions wizards | isn't childrens)\n",
    "p1_neg = ['wizard' in b['description'] for b in data if not (\"Children's Books\" in b['categories'])]\n",
    "p1_neg = sum(p1_neg) * 1.0 / len(p1_neg)\n",
    "\n",
    "# p(mentions witches | is childrens)\n",
    "p2 = ['witch' in b['description'] for b in data if \"Children's Books\" in b['categories']]\n",
    "p2 = sum(p2) * 1.0 / len(p2)\n",
    "\n",
    "# p(mentions witches | isn't childrens)\n",
    "p2_neg = ['witch' in b['description'] for b in data if not (\"Children's Books\" in b['categories'])]\n",
    "p2_neg = sum(p2_neg) * 1.0 / len(p2_neg)\n",
    "\n",
    "# Prediction\n",
    "\n",
    "score = prior * p1 * p2\n",
    "score_neg = prior_neg * p1_neg * p2_neg\n",
    "\n",
    "# Actual ('non-naive') probability\n",
    "\n",
    "p = [\"Children's Books\" in b['categories'] for b in data if 'witch' in b['description'] and 'wizard' in b['description']]\n",
    "p = sum(p) * 1.0 / len(p)\n",
    "\n",
    "### Logistic Regression -- \"Judging a book by its cover\"\n",
    "\n",
    "print(\"Reading data...\")\n",
    "# Download from http://jmcauley.ucsd.edu/cse255/data/amazon/book_images_5000.json\n",
    "data = list(parseData(\"data/amazon/book_images_5000.json\"))\n",
    "print(\"done\")\n",
    "\n",
    "X = [b['image_feature'] for b in data]\n",
    "y = [\"Children's Books\" in b['categories'] for b in data]\n",
    "\n",
    "X_train = X[:2500]\n",
    "y_train = y[:2500]\n",
    "\n",
    "X_test = X[2500:]\n",
    "y_test = y[2500:]\n",
    "\n",
    "# Create a support vector classifier object, with regularization parameter C = 1000\n",
    "# clf = svm.SVC(C=1000, kernel='linear')\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# train_predictions = clf.predict(X_train)\n",
    "# test_predictions = clf.predict(X_test)\n",
    "\n",
    "# Logistic regression classifier\n",
    "mod = linear_model.LogisticRegression(C=1.0)\n",
    "mod.fit(X_train, y_train)\n",
    "\n",
    "train_predictions = mod.predict(X_train)\n",
    "test_predictions = mod.predict(X_test)\n",
    "\n",
    "\n",
    "### Diagnostics\n",
    "\n",
    "# From https://archive.ics.uci.edu/ml/datasets/Polish+companies+bankruptcy+data\n",
    "f = open(\"5year.arff\", 'r')\n",
    "\n",
    "# Reading in data\n",
    "while not '@data' in f.readline():\n",
    "    pass\n",
    "\n",
    "dataset = []\n",
    "for l in f:\n",
    "    if '?' in l: # Missing entry\n",
    "        continue\n",
    "    l = l.split(',')\n",
    "    values = [1] + [float(x) for x in l]\n",
    "    values[-1] = values[-1] > 0 # Convert to bool\n",
    "    dataset.append(values)\n",
    "\n",
    "# Data setup\n",
    "X = [d[:-1] for d in dataset]\n",
    "y = [d[-1] for d in dataset]\n",
    "\n",
    "# Fit model\n",
    "mod = linear_model.LogisticRegression(C=1.0)\n",
    "mod.fit(X,y)\n",
    "\n",
    "pred = mod.predict(X)\n",
    "\n",
    "# How many positive predictions?\n",
    "sum(pred)\n",
    "\n",
    "# Balanced model\n",
    "mod = linear_model.LogisticRegression(C=1.0, class_weight='balanced')\n",
    "mod.fit(X,y)\n",
    "\n",
    "pred = mod.predict(X)\n",
    "\n",
    "# How many positive predictions?\n",
    "sum(pred)\n",
    "\n",
    "# Train/validation/test splits\n",
    "\n",
    "# Shuffle the data\n",
    "Xy = list(zip(X,y))\n",
    "random.shuffle(Xy)\n",
    "\n",
    "X = [d[0] for d in Xy]\n",
    "y = [d[1] for d in Xy]\n",
    "\n",
    "N = len(y)\n",
    "\n",
    "Ntrain = 1000\n",
    "Nvalid = 1000\n",
    "Ntest = 1031\n",
    "\n",
    "Xtrain = X[:Ntrain]\n",
    "Xvalid = X[Ntrain:Ntrain+Nvalid]\n",
    "Xtest = X[Ntrain+Nvalid:]\n",
    "\n",
    "ytrain = y[:Ntrain]\n",
    "yvalid = y[Ntrain:Ntrain+Nvalid]\n",
    "ytest = y[Ntrain+Nvalid:]\n",
    "\n",
    "mod.fit(Xtrain, ytrain)\n",
    "\n",
    "pred = mod.predict(Xtest)\n",
    "\n",
    "correct = pred == ytest\n",
    "\n",
    "# True positives, false positives, etc.\n",
    "\n",
    "TP_ = numpy.logical_and(pred, ytest)\n",
    "FP_ = numpy.logical_and(pred, numpy.logical_not(ytest))\n",
    "TN_ = numpy.logical_and(numpy.logical_not(pred), numpy.logical_not(ytest))\n",
    "FN_ = numpy.logical_and(numpy.logical_not(pred), ytest)\n",
    "\n",
    "TP = sum(TP_)\n",
    "FP = sum(FP_)\n",
    "TN = sum(TN_)\n",
    "FN = sum(FN_)\n",
    "\n",
    "# accuracy\n",
    "sum(correct) / len(correct)\n",
    "(TP + TN) / (TP + FP + TN + FN)\n",
    "\n",
    "# BER\n",
    "1 - 0.5 * (TP / (TP + FN) + TN / (TN + FP))\n",
    "\n",
    "# Ranking\n",
    "\n",
    "scores = mod.decision_function(Xtest)\n",
    "\n",
    "scores_labels = list(zip(scores, ytest))\n",
    "scores_labels.sort(reverse = True)\n",
    "\n",
    "sortedlabels = [x[1] for x in scores_labels]\n",
    "\n",
    "# precision / recall\n",
    "retrieved = sum(pred)\n",
    "relevant = sum(y)\n",
    "intersection = sum([y and p for y,p in zip(ytest,pred)])\n",
    "\n",
    "precision = intersection / retrieved\n",
    "recall = intersection / relevant\n",
    "\n",
    "# precision at 10\n",
    "sum(sortedlabels[:10]) / 10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
