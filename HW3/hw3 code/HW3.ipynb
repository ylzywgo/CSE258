{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGz(path):\n",
    "    for l in gzip.open(path, 'rt'):\n",
    "        yield eval(l)\n",
    "\n",
    "def readCSV(path):\n",
    "    f = gzip.open(path, 'rt')\n",
    "    f.readline()\n",
    "    for l in f:\n",
    "        yield l.strip().split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = []\n",
    "books = []\n",
    "\n",
    "ub_all = defaultdict(set)\n",
    "bu_train = defaultdict(set)\n",
    "ub_train = defaultdict(set)\n",
    "ub_validP = defaultdict(set)\n",
    "popularity = defaultdict(int)\n",
    "\n",
    "totalRead = 190000\n",
    "count = 0\n",
    "\n",
    "for user,book,r in readCSV(\"train_Interactions.csv.gz\"):\n",
    "    count += 1\n",
    "    if not user in users:\n",
    "        users.append(user)\n",
    "    if not book in books:\n",
    "        books.append(book)\n",
    "    ub_all[user].add(book)\n",
    "    if count <= 190000:\n",
    "        ub_train[user].add(book)\n",
    "        bu_train[book].add(user)\n",
    "        popularity[book] += 1\n",
    "    else:\n",
    "        ub_validP[user].add(book)\n",
    "        \n",
    "sortedBook = sorted(popularity.items(), key=lambda x: x[1], reverse = True)\n",
    "\n",
    "validN = defaultdict(set)\n",
    "for user in ub_validP:\n",
    "    for book in ub_validP[user]:\n",
    "        newBook = books[random.randint(0,len(books)-1)]\n",
    "        while (newBook in ub_all[user] or newBook in validN[user]):\n",
    "            newBook = books[random.randint(0,len(books)-1)]\n",
    "        validN[user].add(newBook)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostPop(threshold):\n",
    "    mostpop = []\n",
    "    curRead = 0\n",
    "    for book in sortedBook:\n",
    "        curRead += book[1]\n",
    "        mostpop.append(book[0])\n",
    "        if (curRead > totalRead * threshold):\n",
    "            break\n",
    "    return mostpop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6457\n"
     ]
    }
   ],
   "source": [
    "def mostPopAcc(threshold):\n",
    "    mostPopBook = mostPop(threshold)\n",
    "    error = 0\n",
    "    validNum = 0\n",
    "    for user in ub_validP:\n",
    "        for book in ub_validP[user]:\n",
    "            validNum += 1\n",
    "            if not book in mostPopBook:\n",
    "                error += 1\n",
    "    for user in validN:\n",
    "        for book in validN[user]:\n",
    "            validNum += 1\n",
    "            if book in mostPopBook:\n",
    "                error += 1\n",
    "    accuracy = (validNum - error) / validNum\n",
    "    return accuracy\n",
    "\n",
    "print(mostPopAcc(0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The accuracy of baseline method shows the accuracy of 0.64355"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of baseline method with threshold of 0.50 is 0.64570\n",
      "The accuracy of baseline method with threshold of 0.51 is 0.64555\n",
      "The accuracy of baseline method with threshold of 0.52 is 0.64600\n",
      "The accuracy of baseline method with threshold of 0.53 is 0.64785\n",
      "The accuracy of baseline method with threshold of 0.54 is 0.64905\n",
      "The accuracy of baseline method with threshold of 0.55 is 0.65145\n",
      "The accuracy of baseline method with threshold of 0.56 is 0.65230\n",
      "The accuracy of baseline method with threshold of 0.57 is 0.65250\n",
      "The accuracy of baseline method with threshold of 0.58 is 0.65185\n",
      "The accuracy of baseline method with threshold of 0.59 is 0.65195\n",
      "The accuracy of baseline method with threshold of 0.60 is 0.65185\n",
      "The accuracy of baseline method with threshold of 0.61 is 0.65180\n",
      "The accuracy of baseline method with threshold of 0.62 is 0.65005\n",
      "The accuracy of baseline method with threshold of 0.63 is 0.64960\n",
      "The accuracy of baseline method with threshold of 0.64 is 0.64925\n",
      "The accuracy of baseline method with threshold of 0.65 is 0.64900\n",
      "The accuracy of baseline method with threshold of 0.66 is 0.64685\n",
      "The accuracy of baseline method with threshold of 0.67 is 0.64510\n",
      "The accuracy of baseline method with threshold of 0.68 is 0.64340\n",
      "The accuracy of baseline method with threshold of 0.69 is 0.64245\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0.5, 0.7, 0.01):\n",
    "    print(\"The accuracy of baseline method with threshold of %.2f is %.5f\"%(i,mostPopAcc(i)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. From above, we can know that we can find a better threshold at 0.57, with the accuracy of 0.650005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ub_train_new = defaultdict(set)\n",
    "bu_train_new = defaultdict(set)\n",
    "mostPopBook_new = mostPop(0.57)\n",
    "for user in ub_train:\n",
    "    for book in ub_train[user]:\n",
    "        if book in mostPopBook_new:\n",
    "            ub_train_new[user].add(book)\n",
    "            bu_train_new[book].add(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(s1, s2):\n",
    "    numer = len(s1.intersection(s2))\n",
    "    denom = len(s1.union(s2))\n",
    "    return numer / denom\n",
    "\n",
    "def similarity(user, book):\n",
    "    similarities = []\n",
    "    booklist = []\n",
    "    for otherBook in ub_train[user]: # For all items\n",
    "        if otherBook == book: continue # other than the query\n",
    "        sim = Jaccard(bu_train[book], bu_train[otherBook])\n",
    "        similarities.append((sim,otherBook))\n",
    "    similarities.sort(reverse=True)\n",
    "    return similarities[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def JaccardAcc(threshold):\n",
    "    error = 0\n",
    "    validNum = 0\n",
    "    for user in ub_validP:\n",
    "        for book in ub_validP[user]:\n",
    "            validNum += 1\n",
    "            if similarity(user, book) < threshold:\n",
    "                error += 1\n",
    "    for user in validN:\n",
    "        for book in validN[user]:\n",
    "            validNum += 1\n",
    "            if similarity(user, book) >= threshold:\n",
    "                error += 1\n",
    "    accuracy = (validNum - error) / validNum\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of jaccard-based method with threshold of 0.01 is 0.59715\n",
      "The accuracy of jaccard-based method with threshold of 0.01 is 0.60365\n",
      "The accuracy of jaccard-based method with threshold of 0.01 is 0.60955\n",
      "The accuracy of jaccard-based method with threshold of 0.01 is 0.61630\n",
      "The accuracy of jaccard-based method with threshold of 0.01 is 0.62015\n",
      "The accuracy of jaccard-based method with threshold of 0.01 is 0.62100\n",
      "The accuracy of jaccard-based method with threshold of 0.01 is 0.62270\n",
      "The accuracy of jaccard-based method with threshold of 0.01 is 0.62175\n",
      "The accuracy of jaccard-based method with threshold of 0.01 is 0.62060\n",
      "The accuracy of jaccard-based method with threshold of 0.01 is 0.61590\n",
      "The accuracy of jaccard-based method with threshold of 0.01 is 0.60970\n",
      "The accuracy of jaccard-based method with threshold of 0.02 is 0.60430\n",
      "The accuracy of jaccard-based method with threshold of 0.02 is 0.59730\n",
      "The accuracy of jaccard-based method with threshold of 0.02 is 0.59055\n",
      "The accuracy of jaccard-based method with threshold of 0.02 is 0.58560\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0.005, 0.02, 0.001):\n",
    "    print(\"The accuracy of jaccard-based method with threshold of %.2f is %.5f\"%(i,JaccardAcc(i)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. We can show the performance of Jaccard-based method of different threshold as shown above. The better threshold is at 0.01, with the accuracy of 0.62265."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostPopAndJacAcc(th_mp, th_jc):\n",
    "    error = 0\n",
    "    validNum = 0\n",
    "    mostPopBook = mostPop(th_mp)\n",
    "    for user in ub_validP:\n",
    "        for book in ub_validP[user]:\n",
    "            validNum += 1\n",
    "            if similarity(user, book) < th_jc and not book in mostPopBook:\n",
    "                error += 1\n",
    "    for user in validN:\n",
    "        for book in validN[user]:\n",
    "            validNum += 1\n",
    "            if similarity(user, book) >= th_jc or book in mostPopBook:\n",
    "                error += 1\n",
    "    accuracy = (validNum - error) / validNum\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.62415\n"
     ]
    }
   ],
   "source": [
    "print(mostPopAndJacAcc(0.57, 0.011))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. By combine the baseline method with jaccard-based as shown above, we can get a imporved accuracy of validation set as 0.66275."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = open(\"predictions_Read.txt\", 'w')\n",
    "mostPopBook = mostPop(0.55)\n",
    "for l in open(\"pairs_Read.txt\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        #header\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,b = l.strip().split('-')\n",
    "    if similarity(u, b) >= 0.03 or book in mostPopBook:\n",
    "        predictions.write(u + '-' + b + \",1\\n\")\n",
    "    else:\n",
    "        predictions.write(u + '-' + b + \",0\\n\")\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. The solution is gotten as above. My Kaggle user name is bbylzyw0524"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "allRatings = []\n",
    "userRatings = defaultdict(list)\n",
    "bookRatings = defaultdict(list)\n",
    "user_book = defaultdict(list)\n",
    "book_user = defaultdict(list)\n",
    "valid = []\n",
    "\n",
    "count = 0\n",
    "\n",
    "for user,book,r in readCSV(\"train_Interactions.csv.gz\"):\n",
    "    count += 1\n",
    "    r = int(r)\n",
    "    if count <= 190000:\n",
    "        allRatings.append(r)\n",
    "        userRatings[user].append(r)\n",
    "        bookRatings[book].append(r)\n",
    "        user_book[user].append(book)\n",
    "        book_user[book].append(user)\n",
    "    else:\n",
    "        l = []\n",
    "        l.append(user)\n",
    "        l.append(book)\n",
    "        l.append(r)\n",
    "        valid.append(l)\n",
    "\n",
    "globalAverage = sum(allRatings) / len(allRatings)\n",
    "userAverage = {}\n",
    "for u in userRatings:\n",
    "    userAverage[u] = sum(userRatings[u]) / len(userRatings[u])\n",
    "userSum = {}\n",
    "for u in userRatings:\n",
    "    userSum[u] = sum(userRatings[u])\n",
    "bookSum = {}\n",
    "for b in bookRatings:\n",
    "    bookSum[b] = sum(bookRatings[b])\n",
    "    \n",
    "alpha = globalAverage\n",
    "beta_u = defaultdict(int)\n",
    "beta_b = defaultdict(int)\n",
    "lambda_ = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "for u in userRatings:\n",
    "    beta_u[u] = 0\n",
    "for b in bookRatings:\n",
    "    beta_b[b] = 0\n",
    "    \n",
    "for i in range(100):\n",
    "    sum_beta_u = 0\n",
    "    sum_beta_b = 0\n",
    "#     beta_u_new = defaultdict(int)\n",
    "#     beta_b_new = defaultdict(int)\n",
    "#     for u in userRatings:\n",
    "#         beta_u_new[u] = 0\n",
    "#     for b in bookRatings:\n",
    "#         beta_b_new[b] = 0\n",
    "    for user in user_book:\n",
    "        for book in user_book[user]:\n",
    "            sum_beta_u += beta_u[user]\n",
    "            sum_beta_b += beta_b[book]\n",
    "    alpha = (sum(allRatings) - (sum_beta_b + sum_beta_u)) / 190000\n",
    "    for user in user_book:\n",
    "    #         print(userRatings[user])\n",
    "        sum_ratings_u = userSum[user]\n",
    "    #         print(sum_ratings_u)\n",
    "        numOfBook = len(userRatings[user])\n",
    "#         print(numOfBook)\n",
    "        sum_beta_b = 0\n",
    "        for book in user_book[user]:\n",
    "            sum_beta_b += beta_b[book]\n",
    "        beta_u[user] = (sum_ratings_u - alpha * numOfBook - sum_beta_b) / (lambda_ + numOfBook)\n",
    "    #         print(beta_u_new[user])\n",
    "\n",
    "    for book in book_user:\n",
    "        sum_ratings_b = bookSum[book]\n",
    "        numOfUser = len(bookRatings[book])\n",
    "#         print(numOfUser)\n",
    "        sum_beta_u = 0\n",
    "        for user in book_user[book]:\n",
    "            sum_beta_u += beta_u[user]\n",
    "        beta_b[book] = (sum_ratings_b - alpha * numOfUser - sum_beta_u) / (lambda_ + numOfUser)\n",
    "        \n",
    "#     alpha = alpha_new\n",
    "#     beta_u = beta_u_new\n",
    "#     beta_b = beta_b_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse =  1.1159080829077774\n"
     ]
    }
   ],
   "source": [
    "sum_err = 0\n",
    "for i in valid:\n",
    "    predict_rating = alpha + beta_u[i[0]] + beta_b[i[1]]\n",
    "#     print(predict_rating)\n",
    "    sum_err += (predict_rating - i[2]) ** 2\n",
    "MSE = sum_err / len(valid)\n",
    "print(\"mse = \", MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. The MSE on the validation set is 1.1159080829077774"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_u_num = [beta_u[user] for user in beta_u]\n",
    "beta_b_num = [beta_b[book] for book in beta_b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.7467379856073335 1.3233584115575237\n",
      "-1.7574168637067396 1.4265543793743276\n"
     ]
    }
   ],
   "source": [
    "print(min(beta_u_num), max(beta_u_num))\n",
    "print(min(beta_b_num), max(beta_b_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. The largest and smallest value for beta_u is 1.3233584115575237 and -3.7467379856073335. And the largest and smallest value for beta_b is 1.4265543793743276 and -1.7574168637067396"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = globalAverage\n",
    "beta_u = defaultdict(int)\n",
    "beta_b = defaultdict(int)\n",
    "lambda_ = 3\n",
    "\n",
    "for u in userRatings:\n",
    "    beta_u[u] = 0\n",
    "for b in bookRatings:\n",
    "    beta_b[b] = 0\n",
    "    \n",
    "for i in range(100):\n",
    "    sum_beta_u = 0\n",
    "    sum_beta_b = 0\n",
    "    for user in user_book:\n",
    "        for book in user_book[user]:\n",
    "            sum_beta_u += beta_u[user]\n",
    "            sum_beta_b += beta_b[book]\n",
    "    alpha = (sum(allRatings) - (sum_beta_b + sum_beta_u)) / 190000\n",
    "    for user in user_book:\n",
    "        sum_ratings_u = userSum[user]\n",
    "        numOfBook = len(userRatings[user])\n",
    "        sum_beta_b = 0\n",
    "        for book in user_book[user]:\n",
    "            sum_beta_b += beta_b[book]\n",
    "        beta_u[user] = (sum_ratings_u - alpha * numOfBook - sum_beta_b) / (lambda_ + numOfBook)\n",
    "\n",
    "    for book in book_user:\n",
    "        sum_ratings_b = bookSum[book]\n",
    "        numOfUser = len(bookRatings[book])\n",
    "        sum_beta_u = 0\n",
    "        for user in book_user[book]:\n",
    "            sum_beta_u += beta_u[user]\n",
    "        beta_b[book] = (sum_ratings_b - alpha * numOfUser - sum_beta_u) / (lambda_ + numOfUser)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse =  1.1080652410692764\n"
     ]
    }
   ],
   "source": [
    "sum_err = 0\n",
    "for i in valid:\n",
    "    predict_rating = alpha + beta_u[i[0]] + beta_b[i[1]]\n",
    "#     print(predict_rating)\n",
    "    sum_err += (predict_rating - i[2]) ** 2\n",
    "MSE = sum_err / len(valid)\n",
    "print(\"mse = \", MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. I choose the $\\lambda$ = 3. And the MSE on the validation set is 1.1080652410692764. We get the ratings of test data as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = open(\"predictions_Rating.txt\", 'w')\n",
    "for l in open(\"pairs_Rating.txt\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        #header\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,b = l.strip().split('-')\n",
    "    if u in userRatings and b in bookRatings:\n",
    "        predict_rating = alpha + beta_u[u] + beta_b[b]\n",
    "        predictions.write(u + '-' + b + ',' + str(predict_rating) + '\\n')\n",
    "    elif u in userRatings:\n",
    "        predict_rating = alpha + beta_u[u]\n",
    "        predictions.write(u + '-' + b + ',' + str(predict_rating) + '\\n')\n",
    "    elif b in bookRatings:\n",
    "        predict_rating = alpha + beta_b[b]\n",
    "        predictions.write(u + '-' + b + ',' + str(predict_rating) + '\\n')\n",
    "    else:\n",
    "        predict_rating = alpha\n",
    "        predictions.write(u + '-' + b + ',' + str(predict_rating) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
