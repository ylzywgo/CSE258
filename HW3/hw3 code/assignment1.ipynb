{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGz(path):\n",
    "    for l in gzip.open(path, 'rt'):\n",
    "        yield eval(l)\n",
    "\n",
    "def readCSV(path):\n",
    "    f = gzip.open(path, 'rt')\n",
    "    f.readline()\n",
    "    for l in f:\n",
    "        yield l.strip().split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-10ab386fcbff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbook\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreadCSV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train_Interactions.csv.gz\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0muser\u001b[0m \u001b[0;32min\u001b[0m \u001b[0musers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0musers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "users = []\n",
    "books = []\n",
    "\n",
    "ub_all = defaultdict(set)\n",
    "bu_train = defaultdict(set)\n",
    "ub_train = defaultdict(set)\n",
    "ub_validP = defaultdict(set)\n",
    "popularity = defaultdict(int)\n",
    "\n",
    "totalRead = 180000\n",
    "count = 0\n",
    "\n",
    "for user,book,r in readCSV(\"train_Interactions.csv.gz\"):\n",
    "    count += 1\n",
    "    if not user in users:\n",
    "        users.append(user)\n",
    "    if not book in books:\n",
    "        books.append(book)\n",
    "    ub_all[user].add(book)\n",
    "    if count <= 190000:\n",
    "        ub_train[user].add(book)\n",
    "        bu_train[book].add(user)\n",
    "        popularity[book] += 1\n",
    "    else:\n",
    "        ub_validP[user].add(book)\n",
    "        \n",
    "sortedBook = sorted(popularity.items(), key=lambda x: x[1], reverse = True)\n",
    "\n",
    "validN = defaultdict(set)\n",
    "for user in ub_validP:\n",
    "    for book in ub_validP[user]:\n",
    "        newBook = books[random.randint(0,len(books)-1)]\n",
    "        while (newBook in ub_all[user] or newBook in validN[user]):\n",
    "            newBook = books[random.randint(0,len(books)-1)]\n",
    "        validN[user].add(newBook)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostPop(threshold):\n",
    "    mostpop = []\n",
    "    curRead = 0\n",
    "    for book in sortedBook:\n",
    "        curRead += book[1]\n",
    "        mostpop.append(book[0])\n",
    "        if (curRead > totalRead * threshold):\n",
    "            break\n",
    "    return mostpop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostPopAcc(threshold):\n",
    "    mostPopBook = mostPop(threshold)\n",
    "    error = 0\n",
    "    validNum = 0\n",
    "    for user in ub_validP:\n",
    "        for book in ub_validP[user]:\n",
    "            validNum += 1\n",
    "            if not book in mostPopBook:\n",
    "                error += 1\n",
    "    for user in validN:\n",
    "        for book in validN[user]:\n",
    "            validNum += 1\n",
    "            if book in mostPopBook:\n",
    "                error += 1\n",
    "    accuracy = (validNum - error) / validNum\n",
    "    return accuracy\n",
    "\n",
    "print(mostPopAcc(0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The accuracy of baseline method shows the accuracy of 0.64355"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in np.arange(0.5, 0.7, 0.01):\n",
    "    print(\"The accuracy of baseline method with threshold of %.2f is %.5f\"%(i,mostPopAcc(i)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. From above, we can know that we can find a better threshold at 0.57, with the accuracy of 0.650005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ub_train_new = defaultdict(set)\n",
    "bu_train_new = defaultdict(set)\n",
    "mostPopBook_new = mostPop(0.57)\n",
    "for user in ub_train:\n",
    "    for book in ub_train[user]:\n",
    "        if book in mostPopBook_new:\n",
    "            ub_train_new[user].add(book)\n",
    "            bu_train_new[book].add(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(s1, s2):\n",
    "    numer = len(s1.intersection(s2))\n",
    "    denom = len(s1.union(s2))\n",
    "    return numer / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(user, book):\n",
    "    similarities = []\n",
    "    booklist = []\n",
    "#     for user in ub_train_new:\n",
    "#         if book in ub_train_new[user]:\n",
    "#             print(list(ub_train_new[user]))\n",
    "#             booklist.extend(list(ub_train_new[user]))\n",
    "#     for otherBook in booklist: # For all items\n",
    "#         if otherBook == book: continue # other than the query\n",
    "#         sim = Jaccard(bu_train_new[book], bu_train_new[otherBook])\n",
    "#         similarities.append((sim,otherBook))\n",
    "    for otherBook in ub_train_new[user]: # For all items\n",
    "        if otherBook == book: continue # other than the query\n",
    "        sim = Jaccard(bu_train_new[book], bu_train_new[otherBook])\n",
    "        similarities.append((sim,otherBook))\n",
    "    similarities.sort(reverse=True)\n",
    "    if (len(similarities) == 0):\n",
    "        return 0\n",
    "    return similarities[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def JaccardAcc(threshold):\n",
    "    error = 0\n",
    "    validNum = 0\n",
    "    for user in ub_validP:\n",
    "        for book in ub_validP[user]:\n",
    "            validNum += 1\n",
    "            if similarity(user, book) < threshold:\n",
    "                error += 1\n",
    "    for user in validN:\n",
    "        for book in validN[user]:\n",
    "            validNum += 1\n",
    "            if similarity(user, book) >= threshold:\n",
    "                error += 1\n",
    "    accuracy = (validNum - error) / validNum\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(0, 0.01, 0.001):\n",
    "    print(\"The accuracy of jaccard-based method with threshold of %.2f is %.5f\"%(i,JaccardAcc(i)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. We can show the performance of Jaccard-based method of different threshold as shown above. The better threshold is at 0.01, with the accuracy of 0.62265."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostPopAndJacAcc(th_jc):\n",
    "    error = 0\n",
    "    validNum = 0\n",
    "    for user in ub_validP:\n",
    "        for book in ub_validP[user]:\n",
    "            validNum += 1\n",
    "            if similarity(user, book) < th_jc:\n",
    "                error += 1\n",
    "    for user in validN:\n",
    "        for book in validN[user]:\n",
    "            validNum += 1\n",
    "            if similarity(user, book) >= th_jc:\n",
    "                error += 1\n",
    "    accuracy = (validNum - error) / validNum\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(mostPopAndJacAcc(0.006))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allN = defaultdict(set)\n",
    "for user in ub_all:\n",
    "    for book in ub_all[user]:\n",
    "        newBook = books[random.randint(0,len(books)-1)]\n",
    "        while (newBook in ub_all[user] or newBook in allN[user]):\n",
    "            newBook = books[random.randint(0,len(books)-1)]\n",
    "        allN[user].add(newBook);\n",
    "        \n",
    "allN_list = list()\n",
    "for user in allN:\n",
    "    for book in allN[user]:\n",
    "        allN_list.append([user, book])\n",
    "\n",
    "random.shuffle(allN_list)\n",
    "count = 0\n",
    "\n",
    "ub_trainN = defaultdict(set)\n",
    "ub_validN = defaultdict(set)\n",
    "for ub in allN_list:\n",
    "    count += 1\n",
    "    user = ub[0]\n",
    "    book = ub[1]\n",
    "    if count <= 190000:\n",
    "        ub_trainN[user].add(book)\n",
    "    else:\n",
    "        ub_validN[user].add(book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(allN_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(allN_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSet = []\n",
    "\n",
    "def similarity(user, book):\n",
    "    similarities = []\n",
    "    for otherBook in ub_train[user]: # For all items\n",
    "        if otherBook == book: continue # other than the query\n",
    "        sim = Jaccard(bu_train[book], bu_train[otherBook])\n",
    "        similarities.append((sim,otherBook))\n",
    "    similarities.sort(reverse=True)\n",
    "#     s = 0\n",
    "    if (len(similarities) == 0):\n",
    "        return 0\n",
    "#     for similarity in similarities:\n",
    "#         s += similarity[0]\n",
    "#     s /= len(similarities)\n",
    "    return similarities[0][0]\n",
    "\n",
    "for user in ub_train:\n",
    "    for book in ub_train[user]:\n",
    "        feature = []\n",
    "        feature.append(popularity[book])\n",
    "        feature.append(similarity(user, book))\n",
    "        data = [feature, 1]\n",
    "        trainSet.append(data)\n",
    "\n",
    "for user in ub_trainN:\n",
    "    for book in ub_trainN[user]:\n",
    "        feature = []\n",
    "        feature.append(popularity[book])\n",
    "        feature.append(similarity(user, book))\n",
    "        data = [feature, 0]\n",
    "        trainSet.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(trainSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainSet[-100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(trainSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = []\n",
    "trainY = []\n",
    "for data in trainSet:\n",
    "    trainX.append(data[0])\n",
    "    trainY.append(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validSet = []\n",
    "for user in ub_validP:\n",
    "    for book in ub_validP[user]:\n",
    "        feature = []\n",
    "        feature.append(popularity[book])\n",
    "        feature.append(similarity(user, book))\n",
    "        data = [feature, 1]\n",
    "        validSet.append(data)\n",
    "\n",
    "for user in ub_validN:\n",
    "    for book in ub_validN[user]:\n",
    "        feature = []\n",
    "        feature.append(popularity[book])\n",
    "        feature.append(similarity(user, book))\n",
    "        data = [feature, 0]\n",
    "        validSet.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validX = []\n",
    "validY = []\n",
    "for data in validSet:\n",
    "    validX.append(data[0])\n",
    "    validY.append(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(trainSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(solver='lbfgs').fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainscore = clf.score(trainX, trainY)\n",
    "validscore = clf.score(validX, validY)\n",
    "print(trainscore, validscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf_2 = svm.SVC(gamma='scale')\n",
    "clf_2.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = open(\"predictions_Read.txt\", 'w')\n",
    "mostPopBook = mostPop(0.55)\n",
    "testX = []\n",
    "test_ub = []\n",
    "for l in open(\"pairs_Read.txt\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        #header\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,b = l.strip().split('-')\n",
    "    feature = [popularity[b], similarity(u,b)]\n",
    "    testX.append(feature)\n",
    "    test_ub.append([u, b])\n",
    "    \n",
    "\n",
    "testY = clf.predict(testX)\n",
    "for i in range(len(test_ub)):\n",
    "    u,b = test_ub[i][0], test_ub[i][1]\n",
    "    if testY[i] == 1:\n",
    "        predictions.write(u + '-' + b + \",1\\n\")\n",
    "    else:\n",
    "        predictions.write(u + '-' + b + \",0\\n\")\n",
    "    \n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. By combine the baseline method with jaccard-based as shown above, we can get a imporved accuracy of validation set as 0.66275."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = open(\"predictions_Read.txt\", 'w')\n",
    "mostPopBook = mostPop(0.55)\n",
    "for l in open(\"pairs_Read.txt\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        #header\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,b = l.strip().split('-')\n",
    "    if similarity(u, b) >= 0.006:\n",
    "        predictions.write(u + '-' + b + \",1\\n\")\n",
    "    else:\n",
    "        predictions.write(u + '-' + b + \",0\\n\")\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. The solution is gotten as above. My Kaggle user name is bbylzyw0524"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allRatings = []\n",
    "userRatings = defaultdict(list)\n",
    "bookRatings = defaultdict(list)\n",
    "user_book = defaultdict(list)\n",
    "book_user = defaultdict(list)\n",
    "valid = []\n",
    "\n",
    "count = 0\n",
    "\n",
    "for user,book,r in readCSV(\"train_Interactions.csv.gz\"):\n",
    "    count += 1\n",
    "    r = int(r)\n",
    "    if count <= 190000:\n",
    "        allRatings.append(r)\n",
    "        userRatings[user].append(r)\n",
    "        bookRatings[book].append(r)\n",
    "        user_book[user].append(book)\n",
    "        book_user[book].append(user)\n",
    "    else:\n",
    "        l = []\n",
    "        l.append(user)\n",
    "        l.append(book)\n",
    "        l.append(r)\n",
    "        valid.append(l)\n",
    "\n",
    "globalAverage = sum(allRatings) / len(allRatings)\n",
    "userAverage = {}\n",
    "for u in userRatings:\n",
    "    userAverage[u] = sum(userRatings[u]) / len(userRatings[u])\n",
    "userSum = {}\n",
    "for u in userRatings:\n",
    "    userSum[u] = sum(userRatings[u])\n",
    "bookSum = {}\n",
    "for b in bookRatings:\n",
    "    bookSum[b] = sum(bookRatings[b])\n",
    "    \n",
    "alpha = globalAverage\n",
    "beta_u = defaultdict(int)\n",
    "beta_b = defaultdict(int)\n",
    "lambda_ = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for u in userRatings:\n",
    "    beta_u[u] = 0\n",
    "for b in bookRatings:\n",
    "    beta_b[b] = 0\n",
    "    \n",
    "for i in range(100):\n",
    "    sum_beta_u = 0\n",
    "    sum_beta_b = 0\n",
    "#     beta_u_new = defaultdict(int)\n",
    "#     beta_b_new = defaultdict(int)\n",
    "#     for u in userRatings:\n",
    "#         beta_u_new[u] = 0\n",
    "#     for b in bookRatings:\n",
    "#         beta_b_new[b] = 0\n",
    "    for user in user_book:\n",
    "        for book in user_book[user]:\n",
    "            sum_beta_u += beta_u[user]\n",
    "            sum_beta_b += beta_b[book]\n",
    "    alpha = (sum(allRatings) - (sum_beta_b + sum_beta_u)) / 190000\n",
    "    for user in user_book:\n",
    "    #         print(userRatings[user])\n",
    "        sum_ratings_u = userSum[user]\n",
    "    #         print(sum_ratings_u)\n",
    "        numOfBook = len(userRatings[user])\n",
    "#         print(numOfBook)\n",
    "        sum_beta_b = 0\n",
    "        for book in user_book[user]:\n",
    "            sum_beta_b += beta_b[book]\n",
    "        beta_u[user] = (sum_ratings_u - alpha * numOfBook - sum_beta_b) / (lambda_ + numOfBook)\n",
    "    #         print(beta_u_new[user])\n",
    "\n",
    "    for book in book_user:\n",
    "        sum_ratings_b = bookSum[book]\n",
    "        numOfUser = len(bookRatings[book])\n",
    "#         print(numOfUser)\n",
    "        sum_beta_u = 0\n",
    "        for user in book_user[book]:\n",
    "            sum_beta_u += beta_u[user]\n",
    "        beta_b[book] = (sum_ratings_b - alpha * numOfUser - sum_beta_u) / (lambda_ + numOfUser)\n",
    "        \n",
    "#     alpha = alpha_new\n",
    "#     beta_u = beta_u_new\n",
    "#     beta_b = beta_b_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_err = 0\n",
    "for i in valid:\n",
    "    predict_rating = alpha + beta_u[i[0]] + beta_b[i[1]]\n",
    "#     print(predict_rating)\n",
    "    sum_err += (predict_rating - i[2]) ** 2\n",
    "MSE = sum_err / len(valid)\n",
    "print(\"mse = \", MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. The MSE on the validation set is 1.1159080829077774"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_u_num = [beta_u[user] for user in beta_u]\n",
    "beta_b_num = [beta_b[book] for book in beta_b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(min(beta_u_num), max(beta_u_num))\n",
    "print(min(beta_b_num), max(beta_b_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. The largest and smallest value for beta_u is 1.3233584115575237 and -3.7467379856073335. And the largest and smallest value for beta_b is 1.4265543793743276 and -1.7574168637067396"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = globalAverage\n",
    "beta_u = defaultdict(int)\n",
    "beta_b = defaultdict(int)\n",
    "lambda_ = 3\n",
    "\n",
    "for u in userRatings:\n",
    "    beta_u[u] = 0\n",
    "for b in bookRatings:\n",
    "    beta_b[b] = 0\n",
    "    \n",
    "for i in range(100):\n",
    "    sum_beta_u = 0\n",
    "    sum_beta_b = 0\n",
    "    for user in user_book:\n",
    "        for book in user_book[user]:\n",
    "            sum_beta_u += beta_u[user]\n",
    "            sum_beta_b += beta_b[book]\n",
    "    alpha = (sum(allRatings) - (sum_beta_b + sum_beta_u)) / 190000\n",
    "    for user in user_book:\n",
    "        sum_ratings_u = userSum[user]\n",
    "        numOfBook = len(userRatings[user])\n",
    "        sum_beta_b = 0\n",
    "        for book in user_book[user]:\n",
    "            sum_beta_b += beta_b[book]\n",
    "        beta_u[user] = (sum_ratings_u - alpha * numOfBook - sum_beta_b) / (lambda_ + numOfBook)\n",
    "\n",
    "    for book in book_user:\n",
    "        sum_ratings_b = bookSum[book]\n",
    "        numOfUser = len(bookRatings[book])\n",
    "        sum_beta_u = 0\n",
    "        for user in book_user[book]:\n",
    "            sum_beta_u += beta_u[user]\n",
    "        beta_b[book] = (sum_ratings_b - alpha * numOfUser - sum_beta_u) / (lambda_ + numOfUser)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_err = 0\n",
    "for i in valid:\n",
    "    predict_rating = alpha + beta_u[i[0]] + beta_b[i[1]]\n",
    "#     print(predict_rating)\n",
    "    sum_err += (predict_rating - i[2]) ** 2\n",
    "MSE = sum_err / len(valid)\n",
    "print(\"mse = \", MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. I choose the $\\lambda$ = 3. And the MSE on the validation set is 1.1080652410692764. We get the ratings of test data as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = open(\"predictions_Rating.txt\", 'w')\n",
    "for l in open(\"pairs_Rating.txt\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        #header\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,b = l.strip().split('-')\n",
    "    if u in userRatings and b in bookRatings:\n",
    "        predict_rating = alpha + beta_u[u] + beta_b[b]\n",
    "        predictions.write(u + '-' + b + ',' + str(predict_rating) + '\\n')\n",
    "    elif u in userRatings:\n",
    "        predict_rating = alpha + beta_u[u]\n",
    "        predictions.write(u + '-' + b + ',' + str(predict_rating) + '\\n')\n",
    "    elif b in bookRatings:\n",
    "        predict_rating = alpha + beta_b[b]\n",
    "        predictions.write(u + '-' + b + ',' + str(predict_rating) + '\\n')\n",
    "    else:\n",
    "        predict_rating = alpha\n",
    "        predictions.write(u + '-' + b + ',' + str(predict_rating) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
